{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6f2797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:29.005851Z",
     "iopub.status.busy": "2022-04-04T18:12:29.004039Z",
     "iopub.status.idle": "2022-04-04T18:12:29.011159Z",
     "shell.execute_reply": "2022-04-04T18:12:29.009155Z"
    }
   },
   "outputs": [],
   "source": [
    "# install pytorch \n",
    "# !pip install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Ox6ecnFOZXVf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:29.022664Z",
     "iopub.status.busy": "2022-04-04T18:12:29.021075Z",
     "iopub.status.idle": "2022-04-04T18:12:33.651808Z",
     "shell.execute_reply": "2022-04-04T18:12:33.652342Z"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1647902734308,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "Ox6ecnFOZXVf",
    "outputId": "e0d4240f-9a36-43d8-918d-2871b5a5e992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test torch version and CUDA device\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "a = torch.Tensor([1]).cuda()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Jqi92Iipg4Oi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.655567Z",
     "iopub.status.busy": "2022-04-04T18:12:33.654980Z",
     "iopub.status.idle": "2022-04-04T18:12:33.657621Z",
     "shell.execute_reply": "2022-04-04T18:12:33.657131Z"
    },
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1647902739321,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "Jqi92Iipg4Oi",
    "outputId": "d90d1074-f3ee-4df2-dab7-8db1b9a260a5"
   },
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7GxwWo5hhDNG",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.660650Z",
     "iopub.status.busy": "2022-04-04T18:12:33.660090Z",
     "iopub.status.idle": "2022-04-04T18:12:33.662433Z",
     "shell.execute_reply": "2022-04-04T18:12:33.662894Z"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1647902741269,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "7GxwWo5hhDNG"
   },
   "outputs": [],
   "source": [
    "# # change to project home directory\n",
    "# import os\n",
    "# os.chdir(\"/content/gdrive/My Drive/object_detection_frcnn_mscoco_boilerplate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DNx5XDfcXGHe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.672990Z",
     "iopub.status.busy": "2022-04-04T18:12:33.672422Z",
     "iopub.status.idle": "2022-04-04T18:12:33.675815Z",
     "shell.execute_reply": "2022-04-04T18:12:33.675315Z"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1647902743993,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "DNx5XDfcXGHe",
    "outputId": "865aeac8-87bf-4941-b7a8-6bf847ae1cd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hasan/Downloads/dark_pattern_project/DLDarkPatterns/object_detection/object_detection_frcnn_mscoco_boilerplate'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f44a319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.679704Z",
     "iopub.status.busy": "2022-04-04T18:12:33.679126Z",
     "iopub.status.idle": "2022-04-04T18:12:33.927249Z",
     "shell.execute_reply": "2022-04-04T18:12:33.926073Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647902745985,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "7f44a319"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e4e3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.934271Z",
     "iopub.status.busy": "2022-04-04T18:12:33.933074Z",
     "iopub.status.idle": "2022-04-04T18:12:33.938737Z",
     "shell.execute_reply": "2022-04-04T18:12:33.937562Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647902748663,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "09e4e3e0"
   },
   "outputs": [],
   "source": [
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8tlOF7KK9Cio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.946098Z",
     "iopub.status.busy": "2022-04-04T18:12:33.944966Z",
     "iopub.status.idle": "2022-04-04T18:12:33.949763Z",
     "shell.execute_reply": "2022-04-04T18:12:33.948564Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647902751324,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "8tlOF7KK9Cio"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118d0c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.956393Z",
     "iopub.status.busy": "2022-04-04T18:12:33.955233Z",
     "iopub.status.idle": "2022-04-04T18:12:33.960228Z",
     "shell.execute_reply": "2022-04-04T18:12:33.959004Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647902757552,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "118d0c34"
   },
   "outputs": [],
   "source": [
    "# path to data and annotation\n",
    "data_dir = 'inference_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2bd16f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.968276Z",
     "iopub.status.busy": "2022-04-04T18:12:33.967089Z",
     "iopub.status.idle": "2022-04-04T18:12:33.974477Z",
     "shell.execute_reply": "2022-04-04T18:12:33.973289Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647902759424,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "fe2bd16f"
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      #                     [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "dataset_test = datasets.ImageFolder(data_dir, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab70728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.983047Z",
     "iopub.status.busy": "2022-04-04T18:12:33.981532Z",
     "iopub.status.idle": "2022-04-04T18:12:33.986409Z",
     "shell.execute_reply": "2022-04-04T18:12:33.985229Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647902765746,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "1ab70728"
   },
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=1,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21996757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:33.994194Z",
     "iopub.status.busy": "2022-04-04T18:12:33.992635Z",
     "iopub.status.idle": "2022-04-04T18:12:33.997649Z",
     "shell.execute_reply": "2022-04-04T18:12:33.996473Z"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1647902768904,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "21996757"
   },
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e6ce42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:34.004965Z",
     "iopub.status.busy": "2022-04-04T18:12:34.003424Z",
     "iopub.status.idle": "2022-04-04T18:12:34.008155Z",
     "shell.execute_reply": "2022-04-04T18:12:34.006940Z"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1647902774964,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "f0e6ce42"
   },
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WvHFSK-V14_f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:34.016838Z",
     "iopub.status.busy": "2022-04-04T18:12:34.015675Z",
     "iopub.status.idle": "2022-04-04T18:12:35.638586Z",
     "shell.execute_reply": "2022-04-04T18:12:35.639036Z"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1647902786330,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "WvHFSK-V14_f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.load_state_dict(torch.load('chkpnt1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KOZSKfMe2QAf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:35.645613Z",
     "iopub.status.busy": "2022-04-04T18:12:35.644970Z",
     "iopub.status.idle": "2022-04-04T18:12:35.648278Z",
     "shell.execute_reply": "2022-04-04T18:12:35.647769Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647902796867,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "KOZSKfMe2QAf",
    "outputId": "5619a2a2-854d-403f-d2c0-572190409e82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "xbDXfDvs5CeO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-04T18:12:35.656053Z",
     "iopub.status.busy": "2022-04-04T18:12:35.655460Z",
     "iopub.status.idle": "2022-04-04T18:24:39.046762Z",
     "shell.execute_reply": "2022-04-04T18:24:39.046022Z"
    },
    "executionInfo": {
     "elapsed": 107860,
     "status": "ok",
     "timestamp": 1647912328081,
     "user": {
      "displayName": "S.M. Hasan Mansur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17673291696270669151"
     },
     "user_tz": 240
    },
    "id": "xbDXfDvs5CeO",
    "outputId": "2dfae6e6-5195-438b-e2a4-d9057663cfab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= INFERENCE ===========================\n",
      "================== batch ==================\n",
      "filename:  (107)www.linenchest.com_1c3f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasan/anaconda3/envs/dl_dp_obj_det_env/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (146)www.sivanaspirit.com_96c5.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (159)www.victorianplumbing.co.uk_62cc.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[177.4770, 177.6239, 240.4615, 209.7444]]),\n",
      "  'labels': tensor([5]),\n",
      "  'scores': tensor([0.0970])}]\n",
      "inference result\n",
      "{'boxes': [177.4770050048828,\n",
      "           177.62393188476562,\n",
      "           240.4614715576172,\n",
      "           209.74440002441406],\n",
      " 'labels': 5,\n",
      " 'scores': 0.09698802977800369}\n",
      "================== batch ==================\n",
      "filename:  (170)shapermint.com_fcf2.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (177)www.adoreme.com_a719.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (194)www.dressbarn.com_30d1.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (196)www.epicsports.com_5905.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (218)www.naturehills.com_8b1a.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (23)nutrabay.com_5665.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[49.6827, 67.4999, 90.2945, 81.2742]]),\n",
      "  'labels': tensor([5]),\n",
      "  'scores': tensor([0.0891])}]\n",
      "inference result\n",
      "{'boxes': [49.68269729614258,\n",
      "           67.49992370605469,\n",
      "           90.29454040527344,\n",
      "           81.27420806884766],\n",
      " 'labels': 5,\n",
      " 'scores': 0.08914941549301147}\n",
      "================== batch ==================\n",
      "filename:  (233)www.sivanaspirit.com_5b1f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (253)eyedictive.com_5778.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (269)pages.daraz.lk_115d.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[308.8353,  76.6825, 324.6317, 137.4704]]),\n",
      "  'labels': tensor([1]),\n",
      "  'scores': tensor([0.1267])}]\n",
      "inference result\n",
      "{'boxes': [308.8352966308594,\n",
      "           76.68246459960938,\n",
      "           324.6317138671875,\n",
      "           137.4704132080078],\n",
      " 'labels': 1,\n",
      " 'scores': 0.12665331363677979}\n",
      "================== batch ==================\n",
      "filename:  (27)puffy.com_f607.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (273)shapermint.com_35e5.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (274)shapermint.com_ddea.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (275)shapermint.com_b425.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (299)www.autogeek.net_249b.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (305)www.bellamihair.com_5eea.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[  7.5527, 203.9850,  37.1580, 218.4616],\n",
      "        [  6.9186, 204.2314,  38.6153, 218.6313]]),\n",
      "  'labels': tensor([5, 4]),\n",
      "  'scores': tensor([0.3328, 0.0787])}]\n",
      "inference result\n",
      "{'boxes': [7.552682399749756,\n",
      "           203.98504638671875,\n",
      "           37.157981872558594,\n",
      "           218.4615936279297],\n",
      " 'labels': 5,\n",
      " 'scores': 0.33278563618659973}\n",
      "================== batch ==================\n",
      "filename:  (334)www.fanatics.com_cceb.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (337)www.floryday.com_3f1c.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (340)www.forzieri.com_0192.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (343)www.golftown.com_1073.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (345)www.harveynorman.com.sg_3146.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (35)shapermint.com_d46f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (359)www.jjshouse.com_30a7.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (360)www.jjshouse.com_7293.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (383)www.mlsstore.com_7245.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (42)speedcubeshop.com_440a.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (449)www.victorianplumbing.co.uk_7777.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[173.9165, 177.9060, 239.6720, 210.3420],\n",
      "        [154.0554, 166.4841, 254.2983, 210.3792]]),\n",
      "  'labels': tensor([5, 5]),\n",
      "  'scores': tensor([0.9724, 0.6618])}]\n",
      "inference result\n",
      "{'boxes': [173.91648864746094,\n",
      "           177.906005859375,\n",
      "           239.6719970703125,\n",
      "           210.34202575683594],\n",
      " 'labels': 5,\n",
      " 'scores': 0.97244793176651}\n",
      "================== batch ==================\n",
      "filename:  (511)www.yesstyle.com_86d6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (539)www.homewetbar.com_3dec.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (552)www.penningtons.com_6870.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (612)store.yitechnology.com_d93e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (657)www.ashleystewart.com_8285.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (662)www.bcbg.com_a8d3.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (688)www.chicwish.com_4cb6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (69)www.crossrope.com_6d43.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 84.3374,  80.0936, 191.3158,  97.9754],\n",
      "        [ 82.4150,  80.7484, 195.1597,  98.4530]]),\n",
      "  'labels': tensor([5, 4]),\n",
      "  'scores': tensor([0.7808, 0.0770])}]\n",
      "inference result\n",
      "{'boxes': [84.33735656738281,\n",
      "           80.09358215332031,\n",
      "           191.31581115722656,\n",
      "           97.97535705566406],\n",
      " 'labels': 5,\n",
      " 'scores': 0.7807731628417969}\n",
      "================== batch ==================\n",
      "filename:  (708)www.ebay.ca_d3e8.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (723)www.faithful-to-nature.co.za_9b6f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (728)www.finditparts.com_f582.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (782)www.levenger.com_33f7.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (807)www.naturehills.com_bf06.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (818)www.novica.com_1331.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (861)www.roamans.com_9eec.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (862)www.roamans.com_03b3.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (89)www.harveynorman.com.sg_bb02.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (894)www.templeandwebster.com.au_02e7.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (921)www.wolfandbadger.com_c9c9.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (922)www.wolfandbadger.com_6799.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (931)www.zzounds.com_68a4.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (94)www.hotter.com_dcde.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  (963)www.smokecartel.com_6342.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  FRIEND_SPAM_1.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  FRIEND_SPAM_2.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  HIGH_DEMAND_MESSAGE_1.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  HIGH_DEMAND_MESSAGE_2.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  SOCIAL_PYRAMID_1.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_1--messenger-text-and-video-0-11_5c9f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_1--messenger-text-and-video-1-25_9979.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[138.6384,  66.6878, 182.4153, 138.3146]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.2108])}]\n",
      "inference result\n",
      "{'boxes': [138.6383819580078,\n",
      "           66.68780517578125,\n",
      "           182.41531372070312,\n",
      "           138.31463623046875],\n",
      " 'labels': 3,\n",
      " 'scores': 0.21083638072013855}\n",
      "================== batch ==================\n",
      "filename:  communication_10--kik-1-30_e5dd.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_11--firefox-4-32_79cc.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_13--telegram-1-41_c3b3.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_14--hangout-1-26_aedf.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_15--messages-0-6_d2d8.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_16--messenger-free-texting-app-2-8_6078.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_19--Talkatone-4-27_1499.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_19--Talkatone-6-1_4466.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_19--Talkatone-7-7_3541.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_2--whatsapp-2-14_e5de.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_20--call-free-free-online-0-21_7616.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 80.2227, 134.4693, 147.1069, 176.6958]]),\n",
      "  'labels': tensor([4]),\n",
      "  'scores': tensor([0.1462])}]\n",
      "inference result\n",
      "{'boxes': [80.22265625,\n",
      "           134.4692840576172,\n",
      "           147.1068878173828,\n",
      "           176.6958465576172],\n",
      " 'labels': 4,\n",
      " 'scores': 0.1461847871541977}\n",
      "================== batch ==================\n",
      "filename:  communication_20--call-free-free-online-1-51_ce2e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 81.3714, 123.6833, 144.7532, 151.0545]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.0578])}]\n",
      "inference result\n",
      "{'boxes': [81.37140655517578,\n",
      "           123.68331909179688,\n",
      "           144.75315856933594,\n",
      "           151.05445861816406],\n",
      " 'labels': 3,\n",
      " 'scores': 0.057776883244514465}\n",
      "================== batch ==================\n",
      "filename:  communication_20--call-free-free-online-3-43_ec1f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_21--Marco-Polo-1-49_eafd.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_22--viber-2-16_83a4.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_23--Signal-0-44_b60d.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_23--Signal-1-18_a893.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_24--Line-0-7_308e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_24--Line-1-45_e9fc.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[176.8472, 342.3802, 209.8840, 396.7265]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.0543])}]\n",
      "inference result\n",
      "{'boxes': [176.8472137451172,\n",
      "           342.3802490234375,\n",
      "           209.884033203125,\n",
      "           396.7265319824219],\n",
      " 'labels': 3,\n",
      " 'scores': 0.05433434993028641}\n",
      "================== batch ==================\n",
      "filename:  communication_26--Puffin-Browser-0-51_5494.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_26--Puffin-Browser-0-9_da66.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_27--boss-revolution-0-37_221f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[176.4439,  52.8770, 208.5352,  75.7011]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.5111])}]\n",
      "inference result\n",
      "{'boxes': [176.4438934326172,\n",
      "           52.87699890136719,\n",
      "           208.53517150878906,\n",
      "           75.7011489868164],\n",
      " 'labels': 3,\n",
      " 'scores': 0.5111050605773926}\n",
      "================== batch ==================\n",
      "filename:  communication_27--boss-revolution-3-43_dda6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 98.3425, 320.3226, 126.4231, 366.1132]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.1055])}]\n",
      "inference result\n",
      "{'boxes': [98.34248352050781,\n",
      "           320.3226013183594,\n",
      "           126.42314910888672,\n",
      "           366.11322021484375],\n",
      " 'labels': 3,\n",
      " 'scores': 0.10553018748760223}\n",
      "================== batch ==================\n",
      "filename:  communication_28--wechat-3-49_b1ca.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_29--Messenger-0-19_1989.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_29--Messenger-0-26_23dc.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[101.5660,  40.6264, 180.1337, 157.1765]]),\n",
      "  'labels': tensor([3]),\n",
      "  'scores': tensor([0.9417])}]\n",
      "inference result\n",
      "{'boxes': [101.56598663330078,\n",
      "           40.62641143798828,\n",
      "           180.13365173339844,\n",
      "           157.17648315429688],\n",
      " 'labels': 3,\n",
      " 'scores': 0.9416988492012024}\n",
      "================== batch ==================\n",
      "filename:  communication_29--Messenger-0-45_792d.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_29--Messenger-1-11_8b7e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_3--textnow-0-16_24d9.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_3--textnow-0-25_8b45.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_3--textnow-1-8_115e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_3--textnow-5-26_21c0.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_30--Brave-0-12_9c44.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_30--Brave-0-22_8965.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_30--Brave-0-5_b033.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_4--messenger-lite-3-33_e749.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_5--discord-1-19_b02f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_6--yahoo-email-2-51_8868.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_7--groupme-4-22_8baa.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  communication_8--Google-duo-1-46_ba05.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_14--Daily-Pixel---Color-By-Number-6-18_79d8.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_14--Daily-Pixel---Color-By-Number-7-29_82c4.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_14--Daily-Pixel---Color-By-Number-7-49_5329.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_16--Color-by-Number-3-21_5060.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_16--Color-by-Number-4-39_0423.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-0-21_5fda.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-0-58_e91a.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-0-7_b147.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-2-40_3ce2.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-4-30_cc29.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_19--Face-Secret-Master-5-15_5310.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_2--Google-Play-Games-0-17-a_1a70.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 14.2639, 229.8357, 165.0921, 264.7280],\n",
      "        [108.4100, 230.3347, 165.5790, 263.1549],\n",
      "        [ 18.3126, 230.7965, 109.4757, 262.9205]]),\n",
      "  'labels': tensor([4, 4, 5]),\n",
      "  'scores': tensor([0.7846, 0.1481, 0.0594])}]\n",
      "inference result\n",
      "{'boxes': [14.26388931274414,\n",
      "           229.83567810058594,\n",
      "           165.09205627441406,\n",
      "           264.7279968261719],\n",
      " 'labels': 4,\n",
      " 'scores': 0.7846418619155884}\n",
      "================== batch ==================\n",
      "filename:  entertainment_2--Google-Play-Games-0-17-b_c427.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_20--Face-Master-0-44_00a3.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_25--Dollify-4-20_36cb.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_29--Smash-DIY-6-51_9d20.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  entertainment_29--Smash-DIY-7-42_77d6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  forced_continuity_1.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  forced_continuity_2.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_1--Spotify-1-13_d144.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_1--Spotify-1-6_55ff.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-1-35_ed63.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-3-26_a4e9.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-3-35_c5e4.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-4-59_6039.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-5-11_ec94.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-7-22_26e8.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_11--Edijing-mix-8-32_7eda.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_12--Free-Ringtone-0-15_3a76.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_12--Free-Ringtone-0-22_28f6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_13--Free-Music-Download-1-28_bf77.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 63.8499, 359.5432, 163.0615, 384.5972]]),\n",
      "  'labels': tensor([5]),\n",
      "  'scores': tensor([0.8116])}]\n",
      "inference result\n",
      "{'boxes': [63.849945068359375,\n",
      "           359.54315185546875,\n",
      "           163.0614776611328,\n",
      "           384.59716796875],\n",
      " 'labels': 5,\n",
      " 'scores': 0.8115571141242981}\n",
      "================== batch ==================\n",
      "filename:  music_14--Voice-Recorder-1-41_e6bb.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_14--Voice-Recorder-4-55_39ce.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_15--Volume-Booster-0-46_a68c.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_15--Volume-Booster-2-23_d42a.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_15--Volume-Booster-6-38_606b.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_16--Google-Podcast-0-20_c5af.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_17--Free-Music-0-18_37a6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_17--Free-Music-3-8_c3bb.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_17--Free-Music-8-0_a0a2.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_17--Free-Music-8-40_4b8a.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_19--Free-Music-Downloader-0-43_ed0b.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_19--Free-Music-Downloader-1-28_4797.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 63.8499, 359.5432, 163.0615, 384.5972]]),\n",
      "  'labels': tensor([5]),\n",
      "  'scores': tensor([0.8116])}]\n",
      "inference result\n",
      "{'boxes': [63.849945068359375,\n",
      "           359.54315185546875,\n",
      "           163.0614776611328,\n",
      "           384.59716796875],\n",
      " 'labels': 5,\n",
      " 'scores': 0.8115571141242981}\n",
      "================== batch ==================\n",
      "filename:  music_19--Free-Music-Downloader-1-58_b781.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[176.4247,  35.6865, 194.5160,  45.9327]]),\n",
      "  'labels': tensor([4]),\n",
      "  'scores': tensor([0.1358])}]\n",
      "inference result\n",
      "{'boxes': [176.42474365234375,\n",
      "           35.686546325683594,\n",
      "           194.5159912109375,\n",
      "           45.9327278137207],\n",
      " 'labels': 4,\n",
      " 'scores': 0.13580767810344696}\n",
      "================== batch ==================\n",
      "filename:  music_19--Free-Music-Downloader-4-12_1f83.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-0-8_89fe.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-1-24_7b42.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-1-32_8b3d.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-1-6_21ff.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-3-14_3f38.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_2--Youtube-Music-3-57_1da0.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_21--TuneIn-Radio-0-16_e31e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_21--TuneIn-Radio-0-40_582f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_21--TuneIn-Radio-1-14_6762.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_21--TuneIn-Radio-3-24_7184.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_22--Starmaker-0-20_1d76.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_22--Starmaker-3-4_fbeb.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_22--Starmaker-3-8_27d0.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_22--Starmaker-8-1_9e27.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_23--Tidal-2-6_4894.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_24--Simple-Radio-0-20_589f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_24--Simple-Radio-0-8_df32.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_24--Simple-Radio-3-37_c44c.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_24--Simple-Radio-5-40_508d.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_27--Groovepad-1-32_8006.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_27--Groovepad-4-40_4ae0.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[123.3774,  82.0286, 194.6152, 125.7311],\n",
      "        [ 29.4303,  82.0251, 103.7816, 127.5206]]),\n",
      "  'labels': tensor([5, 5]),\n",
      "  'scores': tensor([0.9456, 0.7211])}]\n",
      "inference result\n",
      "{'boxes': [123.37742614746094,\n",
      "           82.02864837646484,\n",
      "           194.615234375,\n",
      "           125.73113250732422],\n",
      " 'labels': 5,\n",
      " 'scores': 0.9456188082695007}\n",
      "================== batch ==================\n",
      "filename:  music_29--Sticher-0-52_6901.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-0-33_8b90.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-2-26_de54.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-2-4_007c.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-6-57_42c1.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-7-37_5fbd.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_3--Drum-Pad-8-18_cf3e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_30--Music-Bass-Equalizer-0-12_24d3.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_30--Music-Bass-Equalizer-0-6_6cef.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_4--SounCloud-0-46-snap3_0d6c.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_6--MP3-Music-Downloader-_-Free-Music-Download-0-14_4df9.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_6--MP3-Music-Downloader-_-Free-Music-Download-0-57_b85e.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([[ 27.2097, 249.9975, 110.6859, 285.5694],\n",
      "        [ 28.4014, 254.8022, 108.0323, 281.8295]]),\n",
      "  'labels': tensor([3, 5]),\n",
      "  'scores': tensor([0.5102, 0.0692])}]\n",
      "inference result\n",
      "{'boxes': [27.209728240966797,\n",
      "           249.9974822998047,\n",
      "           110.6859130859375,\n",
      "           285.56939697265625],\n",
      " 'labels': 3,\n",
      " 'scores': 0.5101668238639832}\n",
      "================== batch ==================\n",
      "filename:  music_8--Free-Music-Unlimited-Offline-0-13_9865.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_8--Free-Music-Unlimited-Offline-0-3_618f.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_8--Free-Music-Unlimited-Offline-4-17_3cb5.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_8--Free-Music-Unlimited-Offline-5-2_b930.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  music_9--AudioMack-0-24_dcf6.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  privacy_zuckering_1.png\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  privacy_zuckering_2.jpg\n",
      "outputs\n",
      "[{'boxes': tensor([], size=(0, 4)),\n",
      "  'labels': tensor([], dtype=torch.int64),\n",
      "  'scores': tensor([])}]\n",
      "inference result\n",
      "{'boxes': None, 'labels': None, 'scores': None}\n",
      "================== batch ==================\n",
      "filename:  roach_motel_1.png\n",
      "outputs\n",
      "[{'boxes': tensor([[164.6440, 152.2714, 225.9053, 168.0609],\n",
      "        [163.1538, 149.2120, 227.5222, 170.3453]]),\n",
      "  'labels': tensor([5, 3]),\n",
      "  'scores': tensor([0.2239, 0.1431])}]\n",
      "inference result\n",
      "{'boxes': [164.64404296875,\n",
      "           152.2713623046875,\n",
      "           225.9053497314453,\n",
      "           168.06094360351562],\n",
      " 'labels': 5,\n",
      " 'scores': 0.22389008104801178}\n"
     ]
    }
   ],
   "source": [
    "print(\"================= INFERENCE ===========================\")\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_result = {}\n",
    "    # for images, labels in data_loader_test:\n",
    "    for i, (images, labels) in enumerate(data_loader_test, 0):\n",
    "        print(\"================== batch ==================\")\n",
    "        sample_fname, _ = data_loader_test.dataset.samples[i]\n",
    "        filename = sample_fname.split(\"/\")[2]\n",
    "        print(\"filename: \", filename)\n",
    "        outputs = model(images)\n",
    "        print(\"outputs\")\n",
    "        pp.pprint(outputs)\n",
    "\n",
    "        # init boxes, labels, scores\n",
    "        boxes = None\n",
    "        labels = None\n",
    "        scores = None\n",
    "        \n",
    "        # get boxes, labels, scores\n",
    "        if len(outputs[0][\"boxes\"]) != 0:\n",
    "          boxes = outputs[0][\"boxes\"][0].numpy().tolist()\n",
    "        if len(outputs[0][\"labels\"]) != 0:\n",
    "          labels = outputs[0][\"labels\"][0].numpy().tolist()\n",
    "        if len(outputs[0][\"scores\"]) != 0:\n",
    "          scores = outputs[0][\"scores\"][0].numpy().tolist()\n",
    "        \n",
    "        # populate JSON\n",
    "        inference_result[\"boxes\"] = boxes\n",
    "        inference_result[\"labels\"] = labels\n",
    "        inference_result[\"scores\"] = scores\n",
    "\n",
    "        print(\"inference result\")\n",
    "        pp.pprint(inference_result)\n",
    "\n",
    "        # write inference result\n",
    "        inference_output_dir = \"./inference_output/\"\n",
    "        inference_output_filename = inference_output_dir + filename.split(\".\")[0] + \".json\"\n",
    "        with open(inference_output_filename, \"w\") as fp:\n",
    "          json.dump(inference_result, fp)\n",
    "        fp.close()\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "WIdPXpVeQh4T",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T18:24:39.051471Z",
     "iopub.status.busy": "2022-04-04T18:24:39.050345Z",
     "iopub.status.idle": "2022-04-04T18:24:39.053370Z",
     "shell.execute_reply": "2022-04-04T18:24:39.052720Z"
    },
    "id": "WIdPXpVeQh4T"
   },
   "outputs": [],
   "source": [
    "# # write inference result\n",
    "# with open('./inference_result.json', 'w') as fp:\n",
    "#   json.dump(inference_result, fp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "object_detection_frcnn_mscoco_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
